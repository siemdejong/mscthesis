\chapter{Theory}

In addition to the theory described in \cref{pt:theory}, this section describes theory only applicable to the \textsc{Skinstression} project.

% --------------------------------------------------
% Label density smoothing
% --------------------------------------------------

\section{Label density smoothing}
The targets calculated with logistic curve fitting result in a non-uniform distribution.
Data imbalance reduces the ability of a neural network to learn outliers.
This may have significant impact on the test results.
To deal with imbalanced data, various techniques have been developed.
One of those techniques is label density smoothing (LDS)~\cite{yang2021delving}.
It is specifically designed for deep neural networks to learn from imbalanced continuous targets.

\newcommand{\edtl}{$\tilde{p}(y')$ }
LDS computes the effective label density distribution,
\begin{equation}
    \tilde{p}(y') = \int_Y k(y, y')p(y)dy,
\end{equation}
where $k(y,y')$ is a symmetric kernel, $p(y)$ the number of label $y$ present in the training data and \edtl the effective density of target label $y'$.
Reweighting the loss function with the inverse (square root) of \edtl addresses target imbalance.
