\section{Theory}

In addition to the theory described in \cref{pt:theory}, this section describes theory only applicable to the \textsc{Skinstression} project.

% --------------------------------------------------
% Label density smoothing
% --------------------------------------------------

\subsection{Label density smoothing}
The targets calculated with logistic curve fitting result in a non-uniform distribution.
Data imbalance reduces the ability of a neural network to learn outliers.
This may have significant impact on the test results.
To deal with imbalanced data, various techniques have been developed.
One of those techniques is label density smoothing (LDS)~\cite{yang2021delving}.
It is specifically designed for deep neural networks to learn from imbalanced continuous targets.

\newcommand{\edtl}{$\tilde{p}(y')$ }
LDS computes the effective label density distribution,
\begin{equation}
    \tilde{p}(y') = \int_Y k(y, y')p(y)dy,
\end{equation}
where $k(y,y')$ is a symmetric kernel, $p(y)$ the number of label $y$ present in the training data and \edtl the effective density of target label $y'$.
Reweighting the loss function with the inverse (square root) of \edtl addresses target imbalance.

\subsection{Goodness of fit}

\subsubsection{Coefficient of determination}\label{subsec:coef_det}
One possible way to quantify how good a fit is, is to calculate the coefficient of determination.
The coefficient of determination of a dataset $y$ and its prediction $f$, is calculated with
\begin{equation}
    R^2 = 1 - \frac{SS_\mathrm{tot}}{SS_\mathrm{res}},
\end{equation}
where
\begin{equation}
    SS_\mathrm{tot} = \sum_i (y_i - \bar{y})^2,
\end{equation}
with $\bar{y}$ the mean of $y$, and
\begin{equation}
    SS_\mathrm{res} = \sum_i (y_i - f_i)^2.
\end{equation}

If $R^2 = 1$, the prediction perfectly fits the data.
There are some caveats to using $R^2$ to determine the goodness of fit.
Most notably, $R^2$ does not indicate whether the model is the correct model or whether there are enough data points to draw a conclusion.
