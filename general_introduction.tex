\section{Deep learning for higher harmonic microscopy}
Insert some text relating the two projects to each other and introduce the overall challenges.

\section{Reporting of clinical artificial intelligence}
The prediction models described here may aid health care providers in estimating the probability of risk that an outcome is present.
The Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD) Initiative developed guidelines to report on such diagnostic models \cite{Collins2015, Moons2015}.
Recent advances in artificial intelligence (AI) apply AI as black box predictive models in health care, often not sufficiently well reported.
Transparent reporting on these black box models builds confidence in using and further developing the models.
This is especially important in health care, where there is a need for automation while trust in AI is yet to be earned.
The TRIPOD statement in its current form is not well-suited for AI prediction models.
The main challenges are with how models are trained and how models can explain themselves, which is often overlooked.
Unlike machine learning (ML) models, AI models learn by recognizing patterns.
These patterns are then used in inference to make a prediction, possibly of clinical value.
A clinician should then be explained how the model came to its conclusion, along with its confidence.
To account for these challenges, an extension for the TRIPOD statement, TRIPOD-AI is currently being developed \cite{Collins2021,Collins2020}.
Reports on the diagnostic models developed in this study aim to adhere to TRIPOD-AI as well as possible\footnote{The reader is invited to use the TRIPOD-AI accompanying PROBAST-AI \cite{Wolff2019a, Wolff2019b, Collins2021} checklist to assess the risk of bias of the predictive models.}.

\section{Structure}
Quick explanation of thesis structure.